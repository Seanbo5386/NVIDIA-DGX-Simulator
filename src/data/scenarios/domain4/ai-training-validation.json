{
  "id": "domain4-ai-validation",
  "title": "End-to-End AI Training Validation",
  "domain": "domain4",
  "difficulty": "advanced",
  "description": "Learn how to perform comprehensive end-to-end validation of AI training workflows on DGX systems. This validates that all system components work together correctly for real AI workloads.",
  "learningObjectives": [
    "Design AI validation test plan",
    "Run single-GPU training test",
    "Run multi-GPU training test",
    "Run multi-node training test",
    "Validate training performance"
  ],
  "faults": [],
  "initialClusterState": {},
  "steps": [
    {
      "id": "step1",
      "title": "Define Validation Objectives",
      "description": "Establish clear objectives for AI training validation.",
      "objectives": [
        "Define test workloads",
        "Set performance targets",
        "Plan validation scope"
      ],
      "expectedCommands": [
        "nvidia-smi",
        "nvidia-smi --query-gpu=name,memory.total --format=csv"
      ],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Must define validation objectives",
          "expectedCommands": ["nvidia-smi", "nvidia-smi --query-gpu"],
          "requireAllCommands": true
        }
      ],
      "hints": [
        "Test single-GPU, multi-GPU, multi-node",
        "Use standard models (ResNet, BERT)",
        "Define throughput targets (images/sec)",
        "Include convergence validation",
        "Plan for different frameworks"
      ],
      "estimatedDuration": 5,
      "documentationLinks": [
        {
          "title": "AI Validation",
          "url": "https://docs.nvidia.com/deeplearning/"
        }
      ]
    },
    {
      "id": "step2",
      "title": "Prepare Container Environment",
      "description": "Set up NGC container with required frameworks.",
      "objectives": [
        "Pull NGC container",
        "Verify GPU access",
        "Check framework versions"
      ],
      "expectedCommands": [
        "docker pull nvcr.io/nvidia/pytorch:24.01-py3",
        "docker run --rm --gpus all nvcr.io/nvidia/pytorch:24.01-py3 python -c 'import torch; print(torch.cuda.device_count())'"
      ],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Must prepare container environment",
          "expectedCommands": ["docker pull nvcr.io/nvidia/pytorch", "docker run --rm --gpus all"],
          "requireAllCommands": true
        }
      ],
      "hints": [
        "Use latest NGC container",
        "Verify all GPUs visible",
        "Check CUDA and cuDNN versions",
        "Test basic tensor operations",
        "Verify NCCL is available"
      ],
      "estimatedDuration": 7,
      "documentationLinks": [
        {
          "title": "NGC Containers",
          "url": "https://catalog.ngc.nvidia.com/"
        }
      ]
    },
    {
      "id": "step3",
      "title": "Run Single-GPU Training Test",
      "description": "Validate basic training on a single GPU.",
      "objectives": [
        "Run simple training loop",
        "Measure throughput",
        "Check for errors"
      ],
      "expectedCommands": [
        "nvidia-smi dmon -s puc -d 1",
        "nvidia-smi"
      ],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Must run single-GPU training",
          "expectedCommands": ["nvidia-smi dmon", "nvidia-smi"],
          "requireAllCommands": true
        }
      ],
      "hints": [
        "Use standard model (ResNet-50)",
        "Synthetic data for isolation",
        "Measure images/second",
        "Compare to published benchmarks",
        "Check GPU utilization (should be 90%+)"
      ],
      "estimatedDuration": 10,
      "documentationLinks": [
        {
          "title": "PyTorch Training",
          "url": "https://pytorch.org/tutorials/"
        }
      ]
    },
    {
      "id": "step4",
      "title": "Run Multi-GPU Training Test",
      "description": "Validate distributed training across all GPUs in a node.",
      "objectives": [
        "Enable distributed training",
        "Scale across 8 GPUs",
        "Measure scaling efficiency"
      ],
      "expectedCommands": [
        "nvidia-smi",
        "nvidia-smi topo -m"
      ],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Must run multi-GPU training",
          "expectedCommands": ["nvidia-smi", "nvidia-smi topo -m"],
          "requireAllCommands": true
        }
      ],
      "hints": [
        "Use PyTorch DDP or Horovod",
        "torchrun --nproc_per_node=8",
        "Expected: 7-7.5x single-GPU throughput",
        "Scaling efficiency = (8-GPU / 8Ã—1-GPU)",
        "Good scaling: >90% efficiency"
      ],
      "estimatedDuration": 10,
      "documentationLinks": [
        {
          "title": "Distributed Training",
          "url": "https://pytorch.org/tutorials/intermediate/ddp_tutorial.html"
        }
      ]
    },
    {
      "id": "step5",
      "title": "Run Multi-Node Training Test",
      "description": "Validate training across multiple DGX nodes.",
      "objectives": [
        "Configure multi-node launch",
        "Test cross-node communication",
        "Measure multi-node scaling"
      ],
      "expectedCommands": [
        "ibstat",
        "nvidia-smi"
      ],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Must run multi-node training",
          "expectedCommands": ["ibstat", "nvidia-smi"],
          "requireAllCommands": true
        }
      ],
      "hints": [
        "Use torchrun with rdzv_backend",
        "Slurm: srun --ntasks-per-node=8",
        "NCCL_DEBUG=INFO for verification",
        "Expected: ~90% scaling 2-node",
        "Inter-node bandwidth critical"
      ],
      "estimatedDuration": 12,
      "documentationLinks": [
        {
          "title": "Multi-Node Training",
          "url": "https://pytorch.org/docs/stable/distributed.html"
        }
      ]
    },
    {
      "id": "step6",
      "title": "Validate Training Convergence",
      "description": "Verify that training produces correct results.",
      "objectives": [
        "Run full training epoch",
        "Check loss progression",
        "Validate model accuracy"
      ],
      "expectedCommands": [
        "nvidia-smi",
        "nvidia-smi dmon -s puc"
      ],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Must validate training convergence",
          "expectedCommands": ["nvidia-smi", "nvidia-smi dmon"],
          "requireAllCommands": true
        }
      ],
      "hints": [
        "Loss should decrease over steps",
        "Compare to reference training curves",
        "Check for NaN/Inf in loss",
        "Validate final accuracy",
        "Reproducibility with seed"
      ],
      "estimatedDuration": 10,
      "documentationLinks": [
        {
          "title": "Training Validation",
          "url": "https://docs.nvidia.com/deeplearning/"
        }
      ]
    },
    {
      "id": "step7",
      "title": "Test Checkpointing",
      "description": "Validate checkpoint save and resume functionality.",
      "objectives": [
        "Save checkpoint to storage",
        "Resume from checkpoint",
        "Verify continuity"
      ],
      "expectedCommands": [
        "df -h",
        "ls -la /checkpoints"
      ],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Must test checkpointing",
          "expectedCommands": ["df -h", "ls -la"],
          "requireAllCommands": true
        }
      ],
      "hints": [
        "Save to shared storage",
        "Test resume on different node",
        "Verify training continues correctly",
        "Check optimizer state restored",
        "Measure checkpoint I/O time"
      ],
      "estimatedDuration": 8,
      "documentationLinks": [
        {
          "title": "Checkpointing",
          "url": "https://pytorch.org/tutorials/beginner/saving_loading_models.html"
        }
      ]
    },
    {
      "id": "step8",
      "title": "Document Validation Results",
      "description": "Create comprehensive AI validation report.",
      "objectives": [
        "Compile throughput results",
        "Document scaling efficiency",
        "Provide recommendations"
      ],
      "expectedCommands": [
        "nvidia-smi -q > ai_validation_report.txt",
        "nvidia-smi topo -m >> ai_validation_report.txt"
      ],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Must document validation results",
          "expectedCommands": ["nvidia-smi -q >", "nvidia-smi topo -m >>"],
          "requireAllCommands": true
        }
      ],
      "hints": [
        "Include system configuration",
        "Document all throughput measurements",
        "Calculate scaling efficiency",
        "Note any issues found",
        "Compare to published benchmarks"
      ],
      "estimatedDuration": 8,
      "documentationLinks": [
        {
          "title": "Validation Documentation",
          "url": "https://docs.nvidia.com/dgx/"
        }
      ]
    }
  ],
  "successCriteria": [
    "Defined validation objectives",
    "Prepared container environment",
    "Ran single-GPU training test",
    "Ran multi-GPU training test",
    "Ran multi-node training test",
    "Validated training convergence",
    "Tested checkpointing",
    "Documented validation results"
  ],
  "estimatedTime": 70,
  "prerequisites": ["domain3-container-runtime", "domain4-nccl-test"],
  "tags": ["ai-training", "validation", "distributed", "pytorch", "advanced"]
}
