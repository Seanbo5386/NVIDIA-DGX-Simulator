{
  "id": "domain4-gpu-bandwidth",
  "title": "GPU-to-GPU Bandwidth Validation",
  "domain": "domain4",
  "difficulty": "intermediate",
  "description": "Learn how to validate GPU-to-GPU bandwidth including NVLink peer-to-peer transfers, PCIe host transfers, and GPU Direct RDMA. Bandwidth validation ensures the interconnect fabric is performing correctly.",
  "learningObjectives": [
    "Measure NVLink P2P bandwidth",
    "Test PCIe host-to-device bandwidth",
    "Validate GPU Direct RDMA",
    "Compare results to specifications",
    "Identify bandwidth bottlenecks"
  ],
  "faults": [],
  "initialClusterState": {},
  "steps": [
    {
      "id": "step1",
      "title": "Check GPU Interconnect Topology",
      "description": "Understand the GPU interconnect topology before testing.",
      "objectives": [
        "View GPU topology matrix",
        "Identify NVLink connections",
        "Check PCIe topology"
      ],
      "expectedCommands": [
        "nvidia-smi topo -m",
        "nvidia-smi nvlink --status",
        "lspci -tv | grep -i nvidia"
      ],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Must check interconnect topology",
          "expectedCommands": ["nvidia-smi topo -m", "nvidia-smi nvlink --status"],
          "requireAllCommands": true
        }
      ],
      "hints": [
        "NV# = NVLink connection",
        "SYS = PCIe system connection",
        "PIX = PCIe switch connection",
        "All GPUs should show NVLink to each other",
        "Check for any degraded connections"
      ],
      "estimatedDuration": 5,
      "documentationLinks": [
        {
          "title": "GPU Topology",
          "url": "https://docs.nvidia.com/datacenter/"
        }
      ]
    },
    {
      "id": "step2",
      "title": "Verify NVLink Capabilities",
      "description": "Check NVLink version and theoretical bandwidth.",
      "objectives": [
        "Query NVLink version",
        "Check link count",
        "Calculate theoretical bandwidth"
      ],
      "expectedCommands": [
        "nvidia-smi nvlink --capabilities",
        "nvidia-smi nvlink --status -i 0"
      ],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Must verify NVLink capabilities",
          "expectedCommands": ["nvidia-smi nvlink --capabilities", "nvidia-smi nvlink --status"],
          "requireAllCommands": true
        }
      ],
      "hints": [
        "A100: NVLink 3.0, 12 links, 600 GB/s bidir",
        "H100: NVLink 4.0, 18 links, 900 GB/s bidir",
        "Each link: 50 GB/s (A100) or 50 GB/s (H100)",
        "Check all links are active",
        "Link count x bandwidth = total"
      ],
      "estimatedDuration": 5,
      "documentationLinks": [
        {
          "title": "NVLink Specifications",
          "url": "https://docs.nvidia.com/datacenter/nvlink/"
        }
      ]
    },
    {
      "id": "step3",
      "title": "Test NVLink P2P Bandwidth",
      "description": "Measure peer-to-peer bandwidth between GPUs using NVLink.",
      "objectives": [
        "Enable P2P access",
        "Run P2P bandwidth test",
        "Record results for all pairs"
      ],
      "expectedCommands": [
        "nvidia-smi nvlink --status",
        "nvidia-smi topo -m"
      ],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Must test NVLink P2P bandwidth",
          "expectedCommands": ["nvidia-smi nvlink --status", "nvidia-smi topo -m"],
          "requireAllCommands": true
        }
      ],
      "hints": [
        "Use CUDA p2pBandwidthLatencyTest",
        "Test bidirectional bandwidth",
        "Measure all GPU pairs",
        "Expected: 90%+ of theoretical",
        "Asymmetric results indicate issues"
      ],
      "estimatedDuration": 8,
      "documentationLinks": [
        {
          "title": "P2P Bandwidth",
          "url": "https://docs.nvidia.com/cuda/"
        }
      ]
    },
    {
      "id": "step4",
      "title": "Test Host-to-Device Bandwidth",
      "description": "Measure PCIe bandwidth between CPU and GPU memory.",
      "objectives": [
        "Test pageable memory transfer",
        "Test pinned memory transfer",
        "Compare D2H and H2D"
      ],
      "expectedCommands": [
        "nvidia-smi -q -d PCIE",
        "nvidia-smi --query-gpu=pcie.link.gen.current,pcie.link.width.current --format=csv"
      ],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Must test host-to-device bandwidth",
          "expectedCommands": ["nvidia-smi -q -d PCIE", "nvidia-smi --query-gpu=pcie.link.gen"],
          "requireAllCommands": true
        }
      ],
      "hints": [
        "Use CUDA bandwidthTest",
        "Pinned memory much faster than pageable",
        "PCIe Gen4 x16: ~25 GB/s per direction",
        "PCIe Gen5 x16: ~50 GB/s per direction",
        "Verify link speed and width"
      ],
      "estimatedDuration": 7,
      "documentationLinks": [
        {
          "title": "PCIe Bandwidth",
          "url": "https://docs.nvidia.com/cuda/"
        }
      ]
    },
    {
      "id": "step5",
      "title": "Test GPU Memory Bandwidth",
      "description": "Measure internal GPU memory bandwidth.",
      "objectives": [
        "Run memory bandwidth test",
        "Compare to HBM specification",
        "Identify any degradation"
      ],
      "expectedCommands": [
        "nvidia-smi -q -d MEMORY",
        "nvidia-smi --query-gpu=memory.total --format=csv"
      ],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Must test GPU memory bandwidth",
          "expectedCommands": ["nvidia-smi -q -d MEMORY", "nvidia-smi --query-gpu=memory.total"],
          "requireAllCommands": true
        }
      ],
      "hints": [
        "A100: 2039 GB/s HBM2e",
        "H100: 3350 GB/s HBM3",
        "Use STREAM-like benchmark",
        "ECC reduces effective bandwidth slightly",
        "Should achieve 85%+ of theoretical"
      ],
      "estimatedDuration": 7,
      "documentationLinks": [
        {
          "title": "GPU Memory Bandwidth",
          "url": "https://docs.nvidia.com/cuda/"
        }
      ]
    },
    {
      "id": "step6",
      "title": "Validate GPU Direct RDMA",
      "description": "Test direct data path between GPU and network adapter.",
      "objectives": [
        "Verify GDR support",
        "Test RDMA bandwidth",
        "Compare with CPU path"
      ],
      "expectedCommands": [
        "nvidia-smi topo -m",
        "ibstat",
        "cat /sys/class/infiniband/*/device/numa_node"
      ],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Must validate GPU Direct RDMA",
          "expectedCommands": ["nvidia-smi topo -m", "ibstat"],
          "requireAllCommands": true
        }
      ],
      "hints": [
        "GDR bypasses CPU for GPU-NIC transfers",
        "Check GPU-NIC affinity in topology",
        "Use perftest with --use_cuda",
        "GDR should match IB theoretical",
        "NUMA locality affects performance"
      ],
      "estimatedDuration": 8,
      "documentationLinks": [
        {
          "title": "GPU Direct RDMA",
          "url": "https://docs.nvidia.com/cuda/gpudirect-rdma/"
        }
      ]
    },
    {
      "id": "step7",
      "title": "Check for Bandwidth Degradation",
      "description": "Identify signs of bandwidth issues or degradation.",
      "objectives": [
        "Check NVLink errors",
        "Verify PCIe link status",
        "Look for throttling"
      ],
      "expectedCommands": [
        "nvidia-smi nvlink -e",
        "nvidia-smi -q -d PERFORMANCE",
        "nvidia-smi --query-gpu=clocks.gr,clocks.mem --format=csv"
      ],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Must check for degradation",
          "expectedCommands": ["nvidia-smi nvlink -e", "nvidia-smi -q -d PERFORMANCE"],
          "requireAllCommands": true
        }
      ],
      "hints": [
        "NVLink errors reduce effective bandwidth",
        "PCIe link degradation (x8 vs x16)",
        "Thermal throttling reduces clocks",
        "ECC errors in memory",
        "Compare to baseline measurements"
      ],
      "estimatedDuration": 7,
      "documentationLinks": [
        {
          "title": "Performance Troubleshooting",
          "url": "https://docs.nvidia.com/datacenter/"
        }
      ]
    },
    {
      "id": "step8",
      "title": "Document Bandwidth Results",
      "description": "Record all bandwidth measurements for baseline and reporting.",
      "objectives": [
        "Compile all measurements",
        "Calculate efficiency percentages",
        "Create validation report"
      ],
      "expectedCommands": [
        "nvidia-smi -q > bandwidth_validation_report.txt",
        "nvidia-smi topo -m >> bandwidth_validation_report.txt"
      ],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Must document bandwidth results",
          "expectedCommands": ["nvidia-smi -q >", "nvidia-smi topo -m >>"],
          "requireAllCommands": true
        }
      ],
      "hints": [
        "Include all test conditions",
        "Compare to specifications",
        "Note any deviations",
        "Include timestamp and system info",
        "Use for acceptance testing"
      ],
      "estimatedDuration": 5,
      "documentationLinks": [
        {
          "title": "Validation Documentation",
          "url": "https://docs.nvidia.com/dgx/"
        }
      ]
    }
  ],
  "successCriteria": [
    "Checked GPU interconnect topology",
    "Verified NVLink capabilities",
    "Tested NVLink P2P bandwidth",
    "Tested host-to-device bandwidth",
    "Tested GPU memory bandwidth",
    "Validated GPU Direct RDMA",
    "Checked for bandwidth degradation",
    "Documented bandwidth results"
  ],
  "estimatedTime": 52,
  "prerequisites": ["domain2-nvlink-topo"],
  "tags": ["bandwidth", "nvlink", "pcie", "validation", "performance", "intermediate"]
}
