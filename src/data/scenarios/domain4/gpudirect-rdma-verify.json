{
  "id": "domain4-gpudirect-rdma",
  "title": "GPUDirect RDMA Verification",
  "domain": "domain4",
  "difficulty": "advanced",
  "description": "Verify GPUDirect RDMA is properly configured and working. GPUDirect RDMA allows direct data transfer between GPU memory and network adapters, bypassing CPU and system memory for maximum performance.",
  "learningObjectives": [
    "Understand GPUDirect RDMA requirements",
    "Verify kernel module configuration",
    "Test GPU-NIC peer memory",
    "Measure RDMA performance"
  ],
  "faults": [],
  "initialClusterState": {},
  "steps": [
    {
      "id": "step1",
      "title": "Check GPUDirect RDMA Kernel Module",
      "description": "GPUDirect RDMA requires the nvidia-peermem kernel module to enable peer-to-peer memory access between GPUs and RDMA-capable NICs.",
      "objectives": ["Verify nvidia-peermem is loaded"],
      "expectedCommands": ["lsmod | grep nvidia", "lsmod | grep peermem"],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Check kernel modules",
          "expectedCommands": ["lsmod"],
          "requireAllCommands": true
        }
      ],
      "hints": ["lsmod shows loaded kernel modules"],
      "enhancedHints": [
        {
          "id": "step1-hint1",
          "level": 1,
          "message": "The nvidia-peermem module enables GPUDirect RDMA",
          "trigger": { "type": "time-based", "timeSeconds": 30 }
        },
        {
          "id": "step1-hint2",
          "level": 2,
          "message": "Try: lsmod | grep -E 'nvidia|peermem'",
          "trigger": { "type": "time-based", "timeSeconds": 60 }
        },
        {
          "id": "step1-hint3",
          "level": 3,
          "message": "If not loaded: modprobe nvidia-peermem",
          "trigger": { "type": "time-based", "timeSeconds": 90 }
        }
      ],
      "estimatedDuration": 3,
      "documentationLinks": [
        { "title": "GPUDirect RDMA Documentation", "url": "https://docs.nvidia.com/cuda/gpudirect-rdma/index.html" }
      ]
    },
    {
      "id": "step2",
      "title": "Verify GPU-NIC PCIe Topology",
      "description": "For optimal GPUDirect RDMA performance, GPUs and NICs should be on the same PCIe root complex. Check the topology to identify optimal GPU-NIC pairings.",
      "objectives": ["Check GPU-NIC PCIe relationships"],
      "expectedCommands": ["nvidia-smi topo -m", "lspci -tv"],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "View PCIe topology",
          "expectedCommands": ["nvidia-smi topo", "lspci"],
          "requireAllCommands": false
        }
      ],
      "hints": ["nvidia-smi topo -m shows GPU connectivity matrix"],
      "enhancedHints": [
        {
          "id": "step2-hint1",
          "level": 1,
          "message": "The topology matrix shows GPU to NIC connections",
          "trigger": { "type": "time-based", "timeSeconds": 30 }
        },
        {
          "id": "step2-hint2",
          "level": 2,
          "message": "PIX/PHB = same PCIe switch (fast), SYS = different socket (slower)",
          "trigger": { "type": "time-based", "timeSeconds": 60 }
        }
      ],
      "estimatedDuration": 3
    },
    {
      "id": "step3",
      "title": "Check Mellanox OFED Version",
      "description": "GPUDirect RDMA requires compatible versions of NVIDIA driver, CUDA, and Mellanox OFED. Version mismatches can cause GPUDirect to fail silently.",
      "objectives": ["Verify OFED compatibility"],
      "expectedCommands": ["ofed_info -s", "nvidia-smi --query-gpu=driver_version --format=csv"],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Check OFED version",
          "expectedCommands": ["ofed_info"],
          "requireAllCommands": true
        }
      ],
      "hints": ["ofed_info -s shows MLNX_OFED version"],
      "enhancedHints": [
        {
          "id": "step3-hint1",
          "level": 1,
          "message": "MLNX_OFED must be compatible with NVIDIA driver version",
          "trigger": { "type": "time-based", "timeSeconds": 30 }
        },
        {
          "id": "step3-hint2",
          "level": 2,
          "message": "Check NVIDIA support matrix for version compatibility",
          "trigger": { "type": "time-based", "timeSeconds": 60 }
        }
      ],
      "estimatedDuration": 3,
      "documentationLinks": [
        { "title": "MLNX_OFED Release Notes", "url": "https://docs.nvidia.com/networking/display/MLNXOFEDv531001/Release+Notes" }
      ]
    },
    {
      "id": "step4",
      "title": "Test GPUDirect RDMA with perftest",
      "description": "Use RDMA performance tests with GPU memory to verify GPUDirect is working. The perftest tools support GPU memory when built with CUDA support.",
      "objectives": ["Run GPUDirect bandwidth test"],
      "expectedCommands": ["ib_write_bw --use_cuda", "ib_read_bw --use_cuda"],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Run RDMA benchmark",
          "expectedCommands": ["ib_write_bw", "ib_read_bw"],
          "requireAllCommands": false
        }
      ],
      "hints": ["--use_cuda flag enables GPU memory for RDMA tests"],
      "enhancedHints": [
        {
          "id": "step4-hint1",
          "level": 1,
          "message": "perftest tools support GPU memory via --use_cuda",
          "trigger": { "type": "time-based", "timeSeconds": 30 }
        },
        {
          "id": "step4-hint2",
          "level": 2,
          "message": "Server: ib_write_bw --use_cuda=0\nClient: ib_write_bw --use_cuda=0 <server_ip>",
          "trigger": { "type": "time-based", "timeSeconds": 60 }
        },
        {
          "id": "step4-hint3",
          "level": 3,
          "message": "Expected HDR bandwidth: ~23 GB/s per port",
          "trigger": { "type": "time-based", "timeSeconds": 90 }
        }
      ],
      "estimatedDuration": 5
    },
    {
      "id": "step5",
      "title": "Verify with NCCL Environment Variables",
      "description": "NCCL uses GPUDirect RDMA by default when available. Check NCCL debug output to confirm GPUDirect is being used.",
      "objectives": ["Confirm NCCL uses GPUDirect"],
      "expectedCommands": ["NCCL_DEBUG=INFO nccl-test"],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Run NCCL with debug",
          "expectedCommands": ["nccl-test"],
          "requireAllCommands": true
        }
      ],
      "hints": ["NCCL_DEBUG=INFO shows transport selection"],
      "enhancedHints": [
        {
          "id": "step5-hint1",
          "level": 1,
          "message": "NCCL_DEBUG=INFO shows which transport NCCL selects",
          "trigger": { "type": "time-based", "timeSeconds": 30 }
        },
        {
          "id": "step5-hint2",
          "level": 2,
          "message": "Look for 'NET/IB' or 'NET/RDMA' in debug output",
          "trigger": { "type": "time-based", "timeSeconds": 60 }
        },
        {
          "id": "step5-hint3",
          "level": 3,
          "message": "If GPUDirect fails, NCCL falls back to staging through host memory",
          "trigger": { "type": "time-based", "timeSeconds": 90 }
        }
      ],
      "estimatedDuration": 5,
      "documentationLinks": [
        { "title": "NCCL Environment Variables", "url": "https://docs.nvidia.com/deeplearning/nccl/user-guide/docs/env.html" }
      ]
    },
    {
      "id": "step6",
      "title": "Troubleshoot Common Issues",
      "description": "Common GPUDirect RDMA issues:\n- nvidia-peermem not loaded\n- IOMMU enabled (disable in BIOS or use passthrough mode)\n- ACS enabled on PCIe switches\n- Version mismatch between driver and OFED",
      "objectives": ["Know how to troubleshoot GPUDirect issues"],
      "expectedCommands": ["dmesg | grep -i peer", "cat /proc/cmdline"],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Check for errors",
          "expectedCommands": ["dmesg"],
          "requireAllCommands": true
        }
      ],
      "hints": ["Check dmesg for peermem registration messages"],
      "enhancedHints": [
        {
          "id": "step6-hint1",
          "level": 2,
          "message": "IOMMU can block GPUDirect. Check: cat /proc/cmdline | grep iommu",
          "trigger": { "type": "time-based", "timeSeconds": 45 }
        },
        {
          "id": "step6-hint2",
          "level": 3,
          "message": "ACS (Access Control Services) can also block peer access",
          "trigger": { "type": "time-based", "timeSeconds": 90 }
        }
      ],
      "estimatedDuration": 5
    }
  ],
  "successCriteria": [
    "Verified nvidia-peermem module loaded",
    "Checked GPU-NIC PCIe topology",
    "Verified OFED compatibility",
    "Successfully ran GPUDirect RDMA test",
    "Confirmed NCCL uses GPUDirect",
    "Understand common troubleshooting steps"
  ],
  "estimatedTime": 30,
  "prerequisites": [],
  "tags": ["gpudirect", "rdma", "peer-memory", "infiniband", "performance", "nccl", "domain4"]
}
