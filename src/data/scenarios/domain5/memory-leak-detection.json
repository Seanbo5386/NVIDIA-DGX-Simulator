{
  "id": "domain5-memory-leak",
  "title": "GPU Memory Leak Detection",
  "domain": "domain5",
  "difficulty": "intermediate",
  "description": "Learn how to detect and diagnose GPU memory leaks in AI workloads. Memory leaks can cause training jobs to fail with out-of-memory errors over time.",
  "learningObjectives": [
    "Monitor GPU memory usage",
    "Detect memory leaks",
    "Identify leaking processes",
    "Debug memory issues",
    "Implement prevention strategies"
  ],
  "faults": [
    {
      "type": "memory_leak",
      "gpuIndex": 0,
      "leakRate": "100MB/hour"
    }
  ],
  "initialClusterState": {},
  "steps": [
    {
      "id": "step1",
      "title": "Monitor GPU Memory Usage",
      "description": "Set up continuous monitoring of GPU memory allocation.",
      "objectives": [
        "Check current memory usage",
        "Monitor memory over time",
        "Identify baseline usage"
      ],
      "expectedCommands": [
        "nvidia-smi",
        "nvidia-smi --query-gpu=memory.used,memory.free --format=csv -l 5",
        "nvidia-smi dmon -s m"
      ],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Must monitor GPU memory",
          "expectedCommands": [
            "nvidia-smi",
            "nvidia-smi --query-gpu=memory.used"
          ],
          "requireAllCommands": true
        }
      ],
      "hints": [
        "-l 5 loops every 5 seconds",
        "Watch for increasing memory",
        "dmon -s m for memory metrics",
        "Normal: stable memory usage",
        "Leak: constantly increasing"
      ],
      "estimatedDuration": 5,
      "documentationLinks": [
        {
          "title": "GPU Monitoring",
          "url": "https://docs.nvidia.com/datacenter/"
        }
      ]
    },
    {
      "id": "step2",
      "title": "Identify Processes Using GPU Memory",
      "description": "Find which processes are consuming GPU memory.",
      "objectives": [
        "List GPU processes",
        "Check memory per process",
        "Identify suspicious processes"
      ],
      "expectedCommands": [
        "nvidia-smi --query-compute-apps=pid,process_name,used_memory --format=csv",
        "nvidia-smi pmon -s m"
      ],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Must identify GPU processes",
          "expectedCommands": [
            "nvidia-smi --query-compute-apps",
            "nvidia-smi pmon"
          ],
          "requireAllCommands": true
        }
      ],
      "hints": [
        "pmon shows per-process metrics",
        "Track memory per PID over time",
        "Orphaned processes can leak",
        "Check for zombie processes",
        "Note process names and PIDs"
      ],
      "estimatedDuration": 5,
      "documentationLinks": [
        {
          "title": "Process Monitoring",
          "url": "https://docs.nvidia.com/datacenter/"
        }
      ]
    },
    {
      "id": "step3",
      "title": "Check for Orphaned GPU Contexts",
      "description": "Look for orphaned CUDA contexts that may hold memory.",
      "objectives": [
        "Identify orphaned contexts",
        "Check for crashed processes",
        "Find zombie allocations"
      ],
      "expectedCommands": [
        "nvidia-smi",
        "fuser -v /dev/nvidia*",
        "lsof /dev/nvidia*"
      ],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Must check orphaned contexts",
          "expectedCommands": ["nvidia-smi", "fuser -v /dev/nvidia"],
          "requireAllCommands": true
        }
      ],
      "hints": [
        "Memory used but no process = orphaned",
        "fuser shows who owns devices",
        "Crashed process may leave context",
        "Child processes inherit contexts",
        "Container cleanup issues"
      ],
      "estimatedDuration": 5,
      "documentationLinks": [
        {
          "title": "CUDA Contexts",
          "url": "https://docs.nvidia.com/cuda/"
        }
      ]
    },
    {
      "id": "step4",
      "title": "Use DCGM for Memory Monitoring",
      "description": "Leverage DCGM for detailed memory tracking.",
      "objectives": [
        "Enable DCGM monitoring",
        "Track memory metrics",
        "Set up alerts"
      ],
      "expectedCommands": [
        "dcgmi discovery -l",
        "dcgmi stats --enable",
        "dcgmi stats -g 0 -v"
      ],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Must use DCGM monitoring",
          "expectedCommands": ["dcgmi discovery -l", "dcgmi stats --enable"],
          "requireAllCommands": true
        }
      ],
      "hints": [
        "DCGM provides historical data",
        "Can alert on memory thresholds",
        "GPU memory stats field: DCGM_FI_DEV_FB_USED",
        "Policy violations for high memory",
        "Integration with monitoring systems"
      ],
      "estimatedDuration": 7,
      "documentationLinks": [
        {
          "title": "DCGM",
          "url": "https://docs.nvidia.com/datacenter/dcgm/"
        }
      ]
    },
    {
      "id": "step5",
      "title": "Debug with CUDA Tools",
      "description": "Use CUDA tools to debug memory issues.",
      "objectives": [
        "Understand compute-sanitizer",
        "Check for memory errors",
        "Profile memory usage"
      ],
      "expectedCommands": [
        "nvidia-smi -q -d MEMORY",
        "nvidia-smi --query-gpu=memory.total,memory.used,memory.free --format=csv"
      ],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Must debug with CUDA tools",
          "expectedCommands": [
            "nvidia-smi -q -d MEMORY",
            "nvidia-smi --query-gpu=memory.total"
          ],
          "requireAllCommands": true
        }
      ],
      "hints": [
        "compute-sanitizer memcheck",
        "nsys for profiling",
        "nvprof (deprecated) still useful",
        "Check for unfreed allocations",
        "Profile over training iterations"
      ],
      "estimatedDuration": 7,
      "documentationLinks": [
        {
          "title": "CUDA Tools",
          "url": "https://docs.nvidia.com/cuda/cuda-memcheck/"
        }
      ]
    },
    {
      "id": "step6",
      "title": "Check Framework-Specific Issues",
      "description": "Investigate common framework memory issues.",
      "objectives": [
        "Check PyTorch memory",
        "Verify TensorFlow behavior",
        "Look for known issues"
      ],
      "expectedCommands": [
        "nvidia-smi",
        "python -c 'import torch; print(torch.cuda.memory_summary())'"
      ],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Must check framework issues",
          "expectedCommands": ["nvidia-smi", "python -c"],
          "requireAllCommands": true
        }
      ],
      "hints": [
        "PyTorch: torch.cuda.memory_summary()",
        "TensorFlow: GPU memory growth option",
        "Gradient accumulation can leak",
        "DataLoader workers can leak",
        "Clear cache: torch.cuda.empty_cache()"
      ],
      "estimatedDuration": 7,
      "documentationLinks": [
        {
          "title": "Framework Memory",
          "url": "https://pytorch.org/docs/stable/notes/cuda.html"
        }
      ]
    },
    {
      "id": "step7",
      "title": "Clear Leaked Memory",
      "description": "Attempt to recover leaked GPU memory.",
      "objectives": [
        "Kill leaking processes",
        "Clear GPU contexts",
        "Reset GPU if needed"
      ],
      "expectedCommands": [
        "nvidia-smi --query-compute-apps=pid --format=csv",
        "kill -9 <leaking_pid>",
        "nvidia-smi"
      ],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Must clear leaked memory",
          "expectedCommands": ["nvidia-smi --query-compute-apps", "nvidia-smi"],
          "requireAllCommands": true
        }
      ],
      "hints": [
        "Kill process frees its GPU memory",
        "May need to kill parent process",
        "GPU reset clears all contexts",
        "nvidia-smi -r -i <gpu> for reset",
        "Verify memory freed after"
      ],
      "estimatedDuration": 5,
      "documentationLinks": [
        {
          "title": "Memory Recovery",
          "url": "https://docs.nvidia.com/datacenter/"
        }
      ]
    },
    {
      "id": "step8",
      "title": "Implement Prevention Strategies",
      "description": "Set up monitoring and prevention for future leaks.",
      "objectives": [
        "Set memory limits",
        "Enable monitoring alerts",
        "Document best practices"
      ],
      "expectedCommands": [
        "dcgmi policy -g 0 --set 0,0 --action 1",
        "nvidia-smi --query-gpu=memory.used --format=csv -l 60 >> memory_log.txt &"
      ],
      "validationRules": [
        {
          "type": "command-executed",
          "description": "Must implement prevention",
          "expectedCommands": [
            "dcgmi policy",
            "nvidia-smi --query-gpu=memory.used"
          ],
          "requireAllCommands": true
        }
      ],
      "hints": [
        "DCGM can alert on memory threshold",
        "Log memory usage over time",
        "Implement periodic cleanup",
        "Use memory-efficient techniques",
        "Monitor during long training runs"
      ],
      "estimatedDuration": 7,
      "documentationLinks": [
        {
          "title": "Memory Best Practices",
          "url": "https://docs.nvidia.com/deeplearning/"
        }
      ]
    }
  ],
  "successCriteria": [
    "Monitored GPU memory usage",
    "Identified processes using GPU memory",
    "Checked for orphaned GPU contexts",
    "Used DCGM for memory monitoring",
    "Debugged with CUDA tools",
    "Checked framework-specific issues",
    "Cleared leaked memory",
    "Implemented prevention strategies"
  ],
  "estimatedTime": 48,
  "prerequisites": ["domain1-driver-install"],
  "tags": ["memory", "leak", "debugging", "monitoring", "intermediate"],
  "tier": 2,
  "commandFamilies": ["gpu-monitoring", "diagnostics"],
  "explanationGateId": "gate-domain5-memory-leak"
}
